# -*- coding: utf-8 -*-
"""employee salary prediction .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1je3lG2SO2KK8NSpXMSkgbjt9uOuegcWJ
"""

import pandas as pd
df = pd.read_csv('/content/project.csv')
print(df.head())

import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
# Step 1: Drop columns with too many missing values (more than 50%)
threshold = 0.5
cols_to_keep = df.columns[df.isnull().mean() < threshold]
df = df[cols_to_keep]
# Step 2: Fill missing values inplace
for col in df.columns:
    if df[col].dtype == 'object':
        df[col].fillna(df[col].mode()[0], inplace=True)
    else:
        df[col].fillna(df[col].median(), inplace=True)
# Step 3: Label Encoding for categorical columns inplace
label_encoders = {}
for col in df.select_dtypes(include='object').columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le
# Step 4: Scale numerical columns inplace
scaler = StandardScaler()
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])
# Step 5: Show result
print("Preprocessed Data:")
print(df.head())

# Show all columns with few unique values (likely categorical)
for col in df.columns:
    unique_vals = df[col].nunique()
    if unique_vals < 10:
        print(f"{col} â†’ {unique_vals} unique values â†’ likely target or categorical feature")

for col in df.columns:
    print(f"{col} â†’ Type: {df[col].dtype} â†’ Unique: {df[col].nunique()} â†’ Values: {df[col].unique()[:5]}")

possible_targets = [col for col in df.columns if any(word in col.lower() for word in ['target', 'label', 'class', 'output'])]
print("Possible target columns:", possible_targets)

print(df.corr(numeric_only=True)['workclass'].sort_values(ascending=False))

target_col = 'workclass'
X = df.drop(target_col, axis=1)
y = df[target_col]

feature_cols = ['age', 'fnlwgt', 'gender', 'education', 'marital-status','occupation', 'educational-num','occupation','capital-gain', 'capital-loss' , 'hours-per-week', 'native-country', 'income']  # change as per your dataset
X = df[feature_cols]
y = df['workclass']

print("X (Features):\n", X.head())
print("\ny (Target):\n", y.head())

import pandas as pd
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)
print("Training Features Shape:", X_train.shape)
print("Testing Features Shape:", X_test.shape)
print("Training Target Shape:", y_train.shape)
print("Testing Target Shape:", y_test.shape)

import pandas as pd
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
for col in numeric_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
    print(f"\nColumn: {col}")
    print(f"Number of outliers: {outliers.shape[0]}")
    print(outliers[[col]].head())

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns

# Plot boxplots for each numeric column
for col in numeric_cols:
    plt.figure(figsize=(4, 1.5))
    sns.boxplot(x=df[col], color='skyblue')
    plt.title(f'Boxplot for {col}')
    plt.xlabel(col)
    plt.tight_layout()
    plt.show()

x_col = numeric_cols[0]
y_col = numeric_cols[1]
# Calculate IQR bounds
Q1_x = df[x_col].quantile(0.25)
Q3_x = df[x_col].quantile(0.75)
IQR_x = Q3_x - Q1_x
lower_x, upper_x = Q1_x - 1.5 * IQR_x, Q3_x + 1.5 * IQR_x

Q1_y = df[y_col].quantile(0.25)
Q3_y = df[y_col].quantile(0.75)
IQR_y = Q3_y - Q1_y
lower_y, upper_y = Q1_y - 1.5 * IQR_y, Q3_y + 1.5 * IQR_y

# Find outliers
outliers = df[(df[x_col] < lower_x) | (df[x_col] > upper_x) |
              (df[y_col] < lower_y) | (df[y_col] > upper_y)]

# Plot
plt.figure(figsize=(4,2))
sns.scatterplot(x=df[x_col], y=df[y_col], label='Normal')
sns.scatterplot(x=outliers[x_col], y=outliers[y_col], color='red', label='Outliers')
plt.title(f"Outlier Detection: {x_col} vs {y_col}")
plt.legend()
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score

#  Build the Decision Tree Regressor
model = DecisionTreeRegressor(random_state=42)
model.fit(X_train, y_train)

#  Predict and Evaluate
y_pred = model.predict(X_test)

print("RÂ² Score:", r2_score(y_test, y_pred))
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))

from sklearn.tree import DecisionTreeRegressor
model = DecisionTreeRegressor(max_depth=3, random_state=42)
model.fit(X_train, y_train)

import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

plt.figure(figsize=(30, 20))
plot_tree(
    model,
    feature_names=X.columns,
    filled=True,
    rounded=True,
    fontsize=12,
    max_depth=3   # Visualize only first 3 levels
)
plt.title("Pruned Decision Tree Visualization (Max Depth 3)", fontsize=18)
plt.tight_layout()
plt.show()

y = df['workclass'].astype(int)  # If itâ€™s 0/1 but stored as float

# Predict on the test set
y_pred = model.predict(X_test)

# Show a few predicted vs actual values
comparison_df = pd.DataFrame({
    'Actual': y_test.values,
    'Predicted': y_pred
})

print("Sample Predictions:\n")
print(comparison_df.head(10))

import matplotlib.pyplot as plt

plt.figure(figsize=(5,4))
plt.scatter(y_test, y_pred, color='blue', alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Decision Tree Regression: Actual vs Predicted')
plt.grid(True)
plt.tight_layout()
plt.show()

from sklearn.metrics import r2_score, mean_squared_error

print("RÂ² Score:", r2_score(y_test, y_pred))
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import numpy as np

# Make predictions
y_pred = model.predict(X_test)

# RÂ² Score
r2 = r2_score(y_test, y_pred)

# Mean Squared Error
mse = mean_squared_error(y_test, y_pred)

# Root Mean Squared Error
rmse = np.sqrt(mse)

# Mean Absolute Error
mae = mean_absolute_error(y_test, y_pred)

# Print evaluation results
print("ðŸ“Š Model Evaluation Metrics")
print("---------------------------")
print(f"RÂ² Score         : {r2:.4f}")
print(f"Mean Squared Error (MSE): {mse:.4f}")
print(f"Root Mean Squared Error : {rmse:.4f}")
print(f"Mean Absolute Error (MAE): {mae:.4f}")

from sklearn.tree import DecisionTreeRegressor

model = DecisionTreeRegressor(
    max_depth=4,              # limits number of levels
    min_samples_leaf=10,      # minimum samples per leaf
    min_samples_split=20,     # minimum samples to split a node
    random_state=42
)

model.fit(X_train, y_train)

import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

plt.figure(figsize=(40, 25))  # Large canvas

plot_tree(
    model,
    feature_names=X.columns,
    filled=True,
    rounded=True,
    fontsize=12,
    precision=2
)

plt.title("Pruned Decision Tree Regressor (max_depth=4)", fontsize=18)
plt.tight_layout()
plt.show()



from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeRegressor
param_grid = {
    'max_depth': [2, 4, 6, 8, 10],
    'min_samples_split': [2, 5, 10, 20],
    'min_samples_leaf': [1, 5, 10, 20],
    'criterion': ['squared_error', 'absolute_error']
}



